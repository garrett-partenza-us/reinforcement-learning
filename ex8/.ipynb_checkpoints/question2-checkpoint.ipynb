{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fifteen-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "from tqdm import tqdm\n",
    "from collections import deque\n",
    "from environment import Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "flush-prime",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Hyperparameters\n",
    "action_space = [\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"]\n",
    "rows = 5\n",
    "cols = 5\n",
    "walls = [\n",
    "#     (5, 0),\n",
    "#     (5, 2),\n",
    "#     (5, 3),\n",
    "#     (5, 4),\n",
    "#     (5, 5),\n",
    "#     (4, 5),\n",
    "#     (4, 6),\n",
    "#     (4, 7),\n",
    "#     (4, 9),\n",
    "#     (4, 10),\n",
    "#     (0, 5),\n",
    "#     (2, 5),\n",
    "#     (3, 5),\n",
    "#     (6, 5),\n",
    "#     (7, 5),\n",
    "#     (9, 5),\n",
    "#     (10, 5),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "massive-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment(rows, cols, walls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promotional-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transition():\n",
    "    \n",
    "    def __init__(self, state, action, state_new, reward):\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        self.state_new = state_new\n",
    "        self.reward = reward\n",
    "        \n",
    "class ReplayMemory():\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "uniform-stations",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dqn model clas \n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.lin1 = nn.Linear(2,64)\n",
    "        self.lin2 = nn.Linear(64,4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.lin1(x))\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "measured-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(net, state, epsilon):\n",
    "    greedy = np.random.choice([True, False], p=[1-epsilon, epsilon])\n",
    "    if greedy:\n",
    "        action = torch.argmax(net(torch.tensor(state).float()), dim=0).item()\n",
    "    else:\n",
    "        action = random.choice([0,1,2,3])\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "experienced-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        #hyperparameters\n",
    "        self.exp_replay_size = 100000\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 0.1\n",
    "        self.target_update_steps = 10000\n",
    "        self.train_step_count = 1\n",
    "        self.num_episodes = 5000\n",
    "        self.batch_size = 64\n",
    "        self.train_count = 0\n",
    "        self.steps = 0\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        self.max_moves_per_game = 1000\n",
    "        self.lr = 1e-2\n",
    "        \n",
    "        #networks\n",
    "        self.QNet = DQN()\n",
    "        self.TNet = DQN()\n",
    "        self.optimizer = torch.optim.RMSprop(lr=self.lr, params=self.QNet.parameters())\n",
    "        \n",
    "        #replay buffer\n",
    "        self.ER = ReplayMemory(self.exp_replay_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "textile-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(agent):\n",
    "    \n",
    "    sample_transitions = agent.ER.sample(agent.batch_size)\n",
    "    \n",
    "    #increment train counter\n",
    "    agent.train_count +=1\n",
    "    \n",
    "    #copy weights to target network after every 'target_update_steps' updates\n",
    "    if agent.train_count == agent.target_update_steps:\n",
    "        agent.train_count = 0\n",
    "        agent.TNet = copy.deepcopy(agent.QNet)\n",
    "        \n",
    "    \n",
    "    #calculate q-values and expected values\n",
    "    qp = agent.QNet(torch.tensor([transition.state for transition in sample_transitions]).float())\n",
    "    qp = torch.max(qp, dim=1).values\n",
    "    qn = agent.TNet(torch.tensor([transition.state_new for transition in sample_transitions]).float())\n",
    "    qn = torch.max(qn, dim=1).values\n",
    "    qn = qn + torch.tensor([transition.reward for transition in sample_transitions])\n",
    "    qn = agent.gamma * qn\n",
    "    return agent.loss_func(qp, qn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "moral-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/5000 [00:10<1:20:17,  1.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f82e1388737f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-4487a2cccf2c>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(agent)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mqp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtransition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_transitions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mqp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_new\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtransition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_transitions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mqn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtransition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtransition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_transitions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-acb972620a00>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m                 self._forward_hooks.values()):\n\u001b[0m\u001b[1;32m    893\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = Agent()\n",
    "losses = []\n",
    "steps2finish = []\n",
    "\n",
    "agent.QNet.train()\n",
    "for episode in tqdm(range(agent.num_episodes)):\n",
    "    \n",
    "    environment = Environment(rows, cols, walls)\n",
    "    moves = 0\n",
    "\n",
    "    while moves < agent.max_moves_per_game:\n",
    "        \n",
    "        #observation\n",
    "        state = environment.loc()\n",
    "        action = get_action(agent.QNet, state, agent.epsilon)\n",
    "        reward, terminated = environment.step(action_space[action])\n",
    "        state_new = environment.loc()\n",
    "        #append to replay buffer\n",
    "        agent.ER.push(state, action, state_new, reward)\n",
    "        moves +=1\n",
    "            \n",
    "        #increament step count\n",
    "        agent.steps+=1\n",
    "        if len(agent.ER)>=agent.batch_size:\n",
    "            #train after every 'train_step_count' steps\n",
    "            if agent.steps>=agent.train_step_count:\n",
    "                agent.steps = 0\n",
    "                agent.optimizer.zero_grad()\n",
    "                loss = optimize(agent)\n",
    "                loss.backward()\n",
    "                agent.optimizer.step()\n",
    "                losses.append(loss.item())\n",
    "        \n",
    "        #break when episode is complete\n",
    "        if terminated:\n",
    "            break\n",
    "                \n",
    "    steps2finish.append(moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "familiar-session",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff2c8a96d10>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "million-direction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff2c88dd310>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(steps2finish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "detected-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = np.empty((rows, cols))\n",
    "for row in range(rows):\n",
    "    for col in range(cols):\n",
    "        policy[row][col] = torch.argmax(agent.QNet(torch.tensor((row,col)).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "greenhouse-chassis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 2., 2., 2.],\n",
       "       [2., 2., 2., 2., 2.],\n",
       "       [2., 2., 2., 2., 2.],\n",
       "       [2., 2., 2., 2., 2.],\n",
       "       [2., 2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-content",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
